- name: Fetch Global Leaders Health Data
        shell: python
        run: |
          import json, os, re, urllib.request, urllib.parse
          from datetime import datetime

          def get_val(item, tag):
              match = re.search(f'<{tag}>(.*?)</{tag}>', item, re.DOTALL)
              return match.group(1) if match else ""

          # Arama sorgularını geniş tutuyoruz
          queries = [
              'intitle:"President" (health OR hospital OR medical)',
              'intitle:"Prime Minister" (health OR hospital OR medical)',
              'intitle:"King" (health OR hospital OR medical)',
              'intitle:"Trump" (health OR hospital OR medical)',
              'intitle:"Putin" (health OR hospital OR medical)',
              'intitle:"Cumhurbaşkanı" (sağlık OR hastane OR ameliyat)',
              'intitle:"Başbakan" (sağlık OR hastane OR ameliyat)'
          ]

          def fetch_all():
              collected = []
              for q in queries:
                  encoded_q = urllib.parse.quote(q)
                  # Filtreleri gevşetiyoruz ki daha çok veri gelsin
                  url = f"https://news.google.com/rss/search?q={encoded_q}&hl=en-US"
                  try:
                      req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                      with urllib.request.urlopen(req) as resp:
                          content = resp.read().decode('utf-8')
                          matches = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)
                          for it in matches: # LIMIT KALDIRILDI
                              collected.append({
                                  "title": get_val(it, 'title').replace('<![CDATA[', '').replace(']]>', ''),
                                  "link": get_val(it, 'link'),
                                  "pubDate": get_val(it, 'pubDate')
                              })
                  except: continue
              return collected

          raw_items = fetch_all()
          
          # Mevcut veriyi oku ve yenileriyle birleştir (Tekilleştirerek)
          filename = 'leaders_health.json'
          existing = []
          if os.path.exists(filename):
              with open(filename, 'r', encoding='utf-8') as f:
                  existing = json.load(f).get('items', [])

          seen = {i['link'] for i in existing}
          new_entries = [i for i in raw_items if i['link'] not in seen]
          
          # Sınırı 1000'e çıkardım (Neredeyse sınırsız bir arşiv için)
          final_list = (new_entries + existing)[:1000]

          with open(filename, 'w', encoding='utf-8') as f:
              json.dump({"items": final_list, "last_sync": str(datetime.now())}, f, indent=2, ensure_ascii=False)
