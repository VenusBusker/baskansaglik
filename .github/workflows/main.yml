name: Global Leader Health Records Master
on:
  schedule:
    - cron: '*/30 * * * *' 
  workflow_dispatch:

jobs:
  track:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Fetch Global Leaders Deep Health Data
        shell: python
        run: |
          import json, os, re, urllib.request, urllib.parse
          from datetime import datetime

          def get_val(item, tag):
              match = re.search(f'<{tag}>(.*?)</{tag}>', item, re.DOTALL)
              return match.group(1) if match else ""

          # GENİŞLETİLMİŞ LİDER VE KRİTİK TERİM SORGULARI
          # Her satır ayrı bir derinlikli aramayı temsil eder
          queries = [
              # Türkiye Grubu
              '"Recep Tayyip Erdoğan" (sağlık OR hastane OR ameliyat OR tedavi OR rahatsızlık OR kritik)',
              'Erdoğan (sağlık OR hastane OR ameliyat OR tedavi OR "yoğun bakım")',
              
              # ABD Grubu
              '"Donald Trump" (health OR hospital OR surgery OR medical OR "intensive care" OR "check-up")',
              '"Joe Biden" (health OR hospital OR surgery OR medical OR "cognitive" OR "check-up")',
              
              # Rusya & Çin & Kuzey Kore
              '"Vladimir Putin" (health OR hospital OR surgery OR illness OR treatment OR condition)',
              '"Xi Jinping" (health OR hospital OR surgery OR medical OR treatment)',
              '"Kim Jong Un" (health OR hospital OR surgery OR illness OR "heart")',
              
              # Avrupa & Orta Doğu & Diğer
              '"King Charles" (health OR cancer OR treatment OR hospital OR surgery)',
              '"Netanyahu" (health OR hospital OR surgery OR medical OR pacemaker)',
              '"Ali Khamenei" (health OR hospital OR surgery OR condition)',
              '"Pope Francis" (health OR hospital OR surgery OR respiratory)',
              '"Emmanuel Macron" (health OR hospital OR medical)',
              '"Olaf Scholz" (health OR hospital OR medical)',
              
              # Ünvan Bazlı Küresel Tarama (Herhangi bir lideri yakalamak için)
              'intitle:"President" (hospitalized OR "intensive care" OR surgery OR "medical condition")',
              'intitle:"Prime Minister" (hospitalized OR "intensive care" OR surgery OR "medical condition")',
              'intitle:"King" (hospitalized OR "medical emergency" OR surgery)',
              'intitle:"Cumhurbaşkanı" (hastaneye kaldırıldı OR "yoğun bakım" OR ameliyat OR "sağlık durumu")',
              'intitle:"Başbakan" (hastaneye kaldırıldı OR "yoğun bakım" OR ameliyat OR "sağlık durumu")'
          ]

          def fetch_data():
              collected = []
              for q in queries:
                  # Sorgu diline göre Google News bölgesini seç
                  is_tr = any(x in q for x in ["sağlık", "hastane", "Erdoğan", "Başbakan", "Cumhurbaşkanı"])
                  hl = "tr" if is_tr else "en-US"
                  gl = "TR" if is_tr else "US"
                  
                  encoded_q = urllib.parse.quote(q)
                  url = f"https://news.google.com/rss/search?q={encoded_q}&hl={hl}&gl={gl}"

                  try:
                      req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                      with urllib.request.urlopen(req) as resp:
                          content = resp.read().decode('utf-8')
                          items = re.findall(r'<item>(.*?)</item>', content, re.DOTALL)
                          for it in items:
                              collected.append({
                                  "title": get_val(it, 'title').replace('<![CDATA[', '').replace(']]>', ''),
                                  "link": get_val(it, 'link'),
                                  "pubDate": get_val(it, 'pubDate')
                              })
                  except: continue
              return collected

          raw_data = fetch_data()

          # Arşivi Yönet
          filename = 'leaders_health.json'
          old_items = []
          if os.path.exists(filename):
              try:
                  with open(filename, 'r', encoding='utf-8') as f:
                      old_items = json.load(f).get('items', [])
              except: pass

          # Link üzerinden tekilleştirme (Duplicte önleme)
          existing_links = {i['link'] for i in old_items}
          new_unique = [i for i in raw_data if i['link'] not in existing_links]
          
          # Arşiv sınırını 2000'e çıkarıyoruz (Sınırsıza yakın arşiv)
          final_list = (new_unique + old_items)[:2000]

          with open(filename, 'w', encoding='utf-8') as f:
              json.dump({"items": final_list, "last_update": str(datetime.now())}, f, indent=2, ensure_ascii=False)

      - name: Commit and Push
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "TheRegistryBot"
          git add leaders_health.json
          git commit -m "Comprehensive Health Sync: $(date)" || exit 0
          git push origin main
